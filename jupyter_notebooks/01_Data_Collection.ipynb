{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3a79e6",
   "metadata": {},
   "source": [
    "_This project was developed independently as part of Code Institute’s Predictive Analytics Project. Any datasets or templates used are openly provided by the course or via public sources like Kaggle. All commentary and code logic are my own._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31d988",
   "metadata": {},
   "source": [
    "# Notebook 01: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9575c8f",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The purpose of this notebook is to gather, load, and perform a preliminary inspection of the raw data for the Heritage Housing project. This step ensures we're working with valid data sources, understand their structure, and prepare for cleaning and wrangling in the next phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b7557",
   "metadata": {},
   "source": [
    "### Inputs  \n",
    "- Kaggle API token (`kaggle.json`)  \n",
    "- Dataset from Kaggle: Ames Housing (Code Institute)\n",
    "\n",
    "### Outputs  \n",
    "- `/data/raw/house_prices_records.csv`  \n",
    "- `/data/raw/inherited_houses.csv`  \n",
    "- `/data/raw/house-metadata.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c86f2d",
   "metadata": {},
   "source": [
    "### Change Working Directory\n",
    "\n",
    "- To allow smooth access to the data files, we need to adjust our working directory. \n",
    "- Since this notebook lives in a subfolder (e.g. jupyter_notebooks), we need to change the working directory from its current folder to its parent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e65785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Heritage Housing – Data Collection Script\n",
    "\n",
    "Purpose:\n",
    "This script automates the initial data collection process:\n",
    "- Installs and configures the Kaggle CLI\n",
    "- Downloads the housing dataset from the Code Institute competition page\n",
    "- Extracts the dataset into the project's raw data directory\n",
    "- Loads house price and inherited property data into memory\n",
    "- Provides initial shape and column inspection for both datasets\n",
    "\"\"\"\n",
    "\n",
    "# rest of your code...\n",
    "import os\n",
    "# Smart Working Directory Setup \n",
    "project_root = '/workspaces/heritage_housing'\n",
    "if os.getcwd() != project_root:\n",
    "    try:\n",
    "        os.chdir(project_root)\n",
    "        print(f\"[INFO] Changed working directory to project root: {os.getcwd()}\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"[ERROR] Project root '{project_root}' not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c3051",
   "metadata": {},
   "source": [
    "### Fetch Dataset from Kaggle\n",
    "\n",
    "- To keep the workflow reproducible and professional, we will use Kaggle’s API to programmatically download the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33b841",
   "metadata": {},
   "source": [
    "Setup: Install Kaggle and Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kaggle CLI (if not already installed)\n",
    "!pip3 install kaggle==1.5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669c1de",
   "metadata": {},
   "source": [
    "- You must first create a Kaggle account and generate an API token from your account settings. This will download a kaggle.json file.\n",
    "- Move kaggle.json to the root directory of this repo.\n",
    "- Run the below to register the token and adjust permissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json  # Secure the file\n",
    "assert os.path.exists('kaggle.json'), \"[ERROR] kaggle.json not found. Please place it in the project root.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb66f1",
   "metadata": {},
   "source": [
    "### Download the Dataset\n",
    "\n",
    "- We now fetch the dataset using the CLI. This project uses the \"Heritage Housing Predictor\" dataset from Kaggle competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPath = \"codeinstitute/housing-prices-data\"\n",
    "DestinationFolder = \"data/raw\"\n",
    "\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e5a0c",
   "metadata": {},
   "source": [
    "- Unzip the Downloaded File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "for zip_file in Path(DestinationFolder).glob(\"*.zip\"):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as z:\n",
    "        z.extractall(DestinationFolder)\n",
    "    zip_file.unlink()  # Delete zip file after extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8c556",
   "metadata": {},
   "source": [
    "### Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20eabf3",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic reference used for structure inspection only (used in df.info(), etc.)\n",
    "# To read dataset from the csv file in a Pandas dataframe\n",
    "df = pd.read_csv(f'data/raw/house_prices_records.csv')\n",
    "\n",
    "# Load house sales records\n",
    "house_prices_df = pd.read_csv('data/raw/house_prices_records.csv')\n",
    "\n",
    "# Load inherited houses data\n",
    "inherited_df = pd.read_csv('data/raw/inherited_houses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75422e",
   "metadata": {},
   "source": [
    "### Quick Peek at Each Dataset\n",
    "- This gives us a rough idea of the data shape and the kind of features we’ll be dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- House Prices Data ---\")\n",
    "print(house_prices_df.shape)\n",
    "print(house_prices_df.columns)\n",
    "house_prices_df.head()\n",
    "\n",
    "print(\"\\n--- Inherited Houses Data ---\")\n",
    "print(inherited_df.shape)\n",
    "print(inherited_df.columns)\n",
    "inherited_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8208f10",
   "metadata": {},
   "source": [
    "### Dataframe Summary\n",
    "- the .info() methos can now be called on the dataframe object to read the dataframe summary. The result below presents the output into it's own datadrame for readability purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4fbf8",
   "metadata": {},
   "source": [
    "## Our Initial Observations\n",
    "\n",
    "- house_prices_records.csv contains 1,460 rows and 24 columns. The target variable SalePrice is included.\n",
    "\n",
    "- inherited_houses.csv contains 4 rows and 23 columns — all the same features except for the missing SalePrice column.\n",
    "\n",
    "- No explicit ID column is shared between the datasets, so merging isn’t directly possible.\n",
    "\n",
    "- Features include both numeric (e.g., `LotArea`, `YearBuilt`) and categorical data (e.g., `BsmtExposure`, `KitchenQual`).\n",
    "\n",
    "- Likely nulls in columns like `GarageYrBlt`, `LotFrontage`, and basement features.\n",
    "\n",
    "- Column names match well between datasets — suggesting they're aligned in structure.\n",
    "\n",
    "## Summary of Actions Completed\n",
    "\n",
    "- Changed working directory to project root.\n",
    "\n",
    "- Installed Kaggle CLI and configured authentication.\n",
    "\n",
    "- Programmatically downloaded and extracted all raw data from Kaggle.\n",
    "\n",
    "- Loaded raw datasets and confirmed structural consistency.\n",
    "\n",
    "- Inspected column names, dimensions, and got a feel for data types and formats.\n",
    "\n",
    "- Noted down initial findings to guide the cleaning strategy.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Our acquired raw datasets are now prepared for:\n",
    "\n",
    "\n",
    "### Preprocessing and Data Cleaning:\n",
    "\n",
    "- Address missing values for columns such as `LotFrontage`, `GarageYrBlt`, and `BedroomAbvGr` in house_prices_records.csv.\n",
    "- Examine and deal with columns like `EnclosedPorch` and `WoodDeckSF` that have a lot of null values to ascertain their applicability.\n",
    "- To make integration and analysis easier, align the two datasets' layout and structure.\n",
    "- Where there may be differences, standardize the types of columns (floats vs. integers, for example).\n",
    "\n",
    "### EDA (Exploratory Data Analysis):\n",
    "\n",
    "- To find important features, look into the relationships between house attributes and sale prices in house_prices_records.csv.\n",
    "- Use visual aids, such as heatmaps or scatter plots, to help direct feature selection and model construction.\n",
    "- Examine any connections that might exist between the data in the larger dataset and the characteristics of the inherited homes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
