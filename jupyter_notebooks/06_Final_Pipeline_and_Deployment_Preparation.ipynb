{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5db563f",
   "metadata": {},
   "source": [
    "# 06 Final Pipeline And Deployment Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3248b9",
   "metadata": {},
   "source": [
    "## 1. Objectives\n",
    "\n",
    "This notebook consolidates the final predictive pipeline using the selected model. The goals are:\n",
    "\n",
    "- Load training artefacts and model components\n",
    "- Reconstruct the preprocessing and prediction pipeline\n",
    "- Validate pipeline on test data\n",
    "- Prepare outputs for deployment and dashboards\n",
    "- Serialize final components for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e1dc04",
   "metadata": {},
   "source": [
    "## Change Working Directory\n",
    "- Since it is expected that you would keep the notebooks in a subfolder, you will need to switch the working directory when you run the notebook in the editor.\n",
    "- The working directory must be changed from its current folder to its parent folder.\n",
    "- We wish to change the current directory's parent to the new current directory.\n",
    "- Verify the updated current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7010b7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Changed working directory to project root: /workspaces/heritage_housing\n"
     ]
    }
   ],
   "source": [
    "# Smart Working Directory Setup\n",
    "import os\n",
    "project_root = '/workspaces/heritage_housing'\n",
    "if os.getcwd() != project_root:\n",
    "    try:\n",
    "        os.chdir(project_root)\n",
    "        print(f\"[INFO] Changed working directory to project root: {os.getcwd()}\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"[ERROR] Project root '{project_root}' not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc4797",
   "metadata": {},
   "source": [
    "### Requirements (Import Libraries + Verify + Load Artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d652698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.1.1\n",
      "Joblib version: 1.4.2\n",
      "Train/Test Shapes:\n",
      "X_train: (1168, 30) | y_train: (1168,)\n",
      "X_test : (292, 30) | y_test : (292,)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import datetime  # For any timestamping/logging\n",
    "\n",
    "# Verify Dependencies\n",
    "\n",
    "required_dependencies = {\n",
    "    \"pandas\": \"1.4.2\",\n",
    "    \"numpy\": \"1.24.4\",\n",
    "    \"matplotlib\": \"3.4.3\",\n",
    "    \"seaborn\": \"0.11.2\",\n",
    "    \"joblib\": \"1.4.2\"\n",
    "}\n",
    "\n",
    "installed_dependencies = {}\n",
    "for lib, expected_version in required_dependencies.items():\n",
    "    try:\n",
    "        lib_version = __import__(lib).__version__\n",
    "        installed_dependencies[lib] = lib_version\n",
    "        if lib_version != expected_version:\n",
    "            print(f\"{lib} version mismatch: Expected {expected_version}, found {lib_version}\")\n",
    "        else:\n",
    "            print(f\"{lib} is correctly installed (version {lib_version})\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib} is not installed!\")\n",
    "\n",
    "print(\"\\nInstalled Dependencies:\")\n",
    "print(json.dumps(installed_dependencies, indent=4))\n",
    "\n",
    "# Load Saved Artifacts\n",
    "\n",
    "# Define artifact paths\n",
    "artifacts_paths = {\n",
    "    \"random_forest_model\": \"../outputs/models/random_forest_model.pkl\",\n",
    "    \"xgboost_model\": \"../outputs/models/xgboost_model.pkl\",\n",
    "    \"evaluation_metrics\": \"../outputs/metrics/evaluation_metrics.csv\",\n",
    "    \"feature_importance_rf\": \"../outputs/ft_importance/random_forest_feature_importance.csv\",\n",
    "    \"feature_importance_xgb\": \"../outputs/ft_importance/xgboost_feature_importance.csv\",\n",
    "    \"test_features\": \"../data/processed/final/X_test.csv\",\n",
    "    \"test_target\": \"../data/processed/final/y_test.csv\",\n",
    "}\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    rf_model = joblib.load(artifacts_paths[\"random_forest_model\"])\n",
    "    xgb_model = joblib.load(artifacts_paths[\"xgboost_model\"])\n",
    "    print(\"Models loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "try:\n",
    "    evaluation_metrics = pd.read_csv(artifacts_paths[\"evaluation_metrics\"])\n",
    "    print(\"Evaluation metrics loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading evaluation metrics: {e}\")\n",
    "\n",
    "# Load feature importance\n",
    "try:\n",
    "    feature_importance_rf = pd.read_csv(artifacts_paths[\"feature_importance_rf\"])\n",
    "    feature_importance_xgb = pd.read_csv(artifacts_paths[\"feature_importance_xgb\"])\n",
    "    print(\"Feature importance data loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading feature importance data: {e}\")\n",
    "\n",
    "# Load test features and target\n",
    "try:\n",
    "    test_features = pd.read_csv(artifacts_paths[\"test_features\"])\n",
    "    test_target = pd.read_csv(artifacts_paths[\"test_target\"])\n",
    "    print(\" Test data loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading test data: {e}\")\n",
    "\n",
    "# Quick display\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "display(evaluation_metrics.head())\n",
    "\n",
    "print(\"\\nFeature Importance (Random Forest):\")\n",
    "display(feature_importance_rf.head())\n",
    "\n",
    "print(\"\\nFeature Importance (XGBoost):\")\n",
    "display(feature_importance_xgb.head())\n",
    "\n",
    "print(\"\\nTest Features (5 rows):\")\n",
    "display(test_features.head())\n",
    "\n",
    "print(\"\\nTest Target (5 rows):\")\n",
    "display(test_target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d354f66",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
