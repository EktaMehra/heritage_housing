{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5db563f",
   "metadata": {},
   "source": [
    "# 06 Final Pipeline And Deployment Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3248b9",
   "metadata": {},
   "source": [
    "## 1. Objectives\n",
    "\n",
    "This notebook consolidates the final predictive pipeline using the selected model. The goals are:\n",
    "\n",
    "- Load training artefacts and model components\n",
    "- Reconstruct the preprocessing and prediction pipeline\n",
    "- Validate pipeline on test data\n",
    "- Prepare outputs for deployment and dashboards\n",
    "- Serialize final components for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e1dc04",
   "metadata": {},
   "source": [
    "## Change Working Directory\n",
    "- Since it is expected that you would keep the notebooks in a subfolder, you will need to switch the working directory when you run the notebook in the editor.\n",
    "- The working directory must be changed from its current folder to its parent folder.\n",
    "- We wish to change the current directory's parent to the new current directory.\n",
    "- Verify the updated current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7010b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Working Directory Setup\n",
    "import os\n",
    "project_root = '/workspaces/heritage_housing'\n",
    "if os.getcwd() != project_root:\n",
    "    try:\n",
    "        os.chdir(project_root)\n",
    "        print(f\"[INFO] Changed working directory to project root: {os.getcwd()}\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"[ERROR] Project root '{project_root}' not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc4797",
   "metadata": {},
   "source": [
    "### Requirements (Import Libraries + Verify + Load Artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d652698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version mismatch: Expected 1.4.2, found 2.1.1\n",
      "numpy version mismatch: Expected 1.24.4, found 1.26.1\n",
      "matplotlib version mismatch: Expected 3.4.3, found 3.8.0\n",
      "seaborn version mismatch: Expected 0.11.2, found 0.13.2\n",
      "joblib is correctly installed (version 1.4.2)\n",
      "\n",
      "Installed Dependencies:\n",
      "{\n",
      "    \"pandas\": \"2.1.1\",\n",
      "    \"numpy\": \"1.26.1\",\n",
      "    \"matplotlib\": \"3.8.0\",\n",
      "    \"seaborn\": \"0.13.2\",\n",
      "    \"joblib\": \"1.4.2\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'best_random_forest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     rf_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[43martifacts_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_random_forest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     60\u001b[0m     xgb_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(artifacts_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_gradient_boosting\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'best_random_forest'"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import datetime  # For any timestamping/logging\n",
    "\n",
    "# Verify Dependencies\n",
    "\n",
    "required_dependencies = {\n",
    "    \"pandas\": \"1.4.2\",\n",
    "    \"numpy\": \"1.24.4\",\n",
    "    \"matplotlib\": \"3.4.3\",\n",
    "    \"seaborn\": \"0.11.2\",\n",
    "    \"joblib\": \"1.4.2\"\n",
    "}\n",
    "\n",
    "installed_dependencies = {}\n",
    "for lib, expected_version in required_dependencies.items():\n",
    "    try:\n",
    "        lib_version = __import__(lib).__version__\n",
    "        installed_dependencies[lib] = lib_version\n",
    "        if lib_version != expected_version:\n",
    "            print(f\"{lib} version mismatch: Expected {expected_version}, found {lib_version}\")\n",
    "        else:\n",
    "            print(f\"{lib} is correctly installed (version {lib_version})\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib} is not installed!\")\n",
    "\n",
    "print(\"\\nInstalled Dependencies:\")\n",
    "print(json.dumps(installed_dependencies, indent=4))\n",
    "\n",
    "# Load Saved Artifacts\n",
    "\n",
    "# Define artifact paths\n",
    "artifacts_paths = {\n",
    "    \"random_forest_model\": \"../outputs/models/random_forest_model.pkl\",\n",
    "    \"xgboost_model\": \"../outputs/models/xgboost_model.pkl\",\n",
    "    \"evaluation_metrics\": \"../outputs/metrics/model_evaluation_summmary.csv\",\n",
    "    \"feature_importance_rf\": \"../outputs/ft_importance/random_forest_feature_importance.csv\",\n",
    "    \"feature_importance_xgb\": \"../outputs/ft_importance/xgboost_feature_importance.csv\",\n",
    "    \"test_features\": \"../data/processed/final/X_test.csv\",\n",
    "    \"test_target\": \"../data/processed/final/y_test.csv\",\n",
    "}\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    rf_model = joblib.load(artifacts_paths[\"best_random_forest\"])\n",
    "    xgb_model = joblib.load(artifacts_paths[\"best_gradient_boosting\"])\n",
    "    print(\"Models loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "try:\n",
    "    evaluation_metrics = pd.read_csv(artifacts_paths[\"model_evaluation_summmary\"])\n",
    "    print(\"Evaluation metrics loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading evaluation metrics: {e}\")\n",
    "\n",
    "# Load feature importance\n",
    "try:\n",
    "    feature_importance_rf = pd.read_csv(artifacts_paths[\"feature_importance_rf\"])\n",
    "    feature_importance_xgb = pd.read_csv(artifacts_paths[\"feature_importance_xgb\"])\n",
    "    print(\"Feature importance data loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading feature importance data: {e}\")\n",
    "\n",
    "# Load test features and target\n",
    "try:\n",
    "    test_features = pd.read_csv(artifacts_paths[\"test_features\"])\n",
    "    test_target = pd.read_csv(artifacts_paths[\"test_target\"])\n",
    "    print(\" Test data loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading test data: {e}\")\n",
    "\n",
    "# Quick display\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "display(model_evaluation_summary.head())\n",
    "\n",
    "print(\"\\nFeature Importance (Random Forest):\")\n",
    "display(feature_importance_rf.head())\n",
    "\n",
    "print(\"\\nFeature Importance (XGBoost):\")\n",
    "display(feature_importance_xgb.head())\n",
    "\n",
    "print(\"\\nTest Features (5 rows):\")\n",
    "display(test_features.head())\n",
    "\n",
    "print(\"\\nTest Target (5 rows):\")\n",
    "display(test_target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d354f66",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
